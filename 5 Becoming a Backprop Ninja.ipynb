{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce2919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c296abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3166e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):  \n",
    "    X, Y = [], []\n",
    "  \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01143aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])  \n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte,  Yte  = build_dataset(words[n2:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472752da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad) # cool\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a397ae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C  = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 for exercize, it's useless because of BN\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters: p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef5f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176b8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marconobile/miniconda3/envs/karpathyAI/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400366987/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3411, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n * hprebn.sum(0, keepdim=True) # keep dim to get a matrix composed by the .sum(0) row vector\n",
    "bndiff = hprebn - bnmeani # centering operation\n",
    "bndiff2 = bndiff**2 # first step to compute variance\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # corrected var, note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5 # denominator\n",
    "bnraw = bndiff * bnvar_inv # (x-μ)/sqrt(σ**2+ϵ)\n",
    "hpreact = bngain * bnraw + bnbias # scale_γ* (x-μ)/sqrt(σ**2+ϵ) + shift_β\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb)), see Exercise 2\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability, since exp later with this we're ok\n",
    "counts = norm_logits.exp() # e**zi\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv # col vect where each el is the sum of the unnormalized probs over the row\n",
    "logprobs = probs.log() # logsoftmax \n",
    "\n",
    "loss = -logprobs[range(n), Yb].mean() # increase likelihood of correct log probabilities\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters: p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb3671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32, 3, 10]), torch.Size([32, 30]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we start from the int version of the char, then we pass to their embeddings \n",
    "# and then we concat the embeddings to get the embed version of the 3-len seq of chars\n",
    "Xb.shape, C[Xb].shape, C[Xb].view(C[Xb].shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de542e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([64]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take the activations pre-non-lin and we sum it collapsing the rows i.e. sum vertically to get a row vector \n",
    "# of the same dimensionality of the rows\n",
    "hprebn.shape, hprebn.sum(0).shape, hprebn.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "174e1879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits = log counts -> take max over the row \n",
    "logits.shape, logits.max(1, keepdim=True).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e670addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb].shape # increase likelihood of correct log probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba89e5",
   "metadata": {},
   "source": [
    "# Exercise 1: manual backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448c99e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "# Let's start from:\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "print(logprobs.shape) \n",
    "# for each obs in batch, as output we have the pdist over the outclasses.\n",
    "# for each obs [range(n),] we select the idx of the correct class [, Yb]\n",
    "# which means that for each obs we select the logcount of the correct class, we sum them up and we take\n",
    "# their (negative) mean\n",
    "\n",
    "# IMPO: ONLY THE VALUES THAT ARE HERE CONSIDERED (I.E. THE LOGCOUNTS/LOGITS OF THE CORRECT CLASS GET GRADIENT!!!)\n",
    "# because ONLY the logits/logcounts of the correct class (for each obj) partecipates/contributes in the computation \n",
    "# of the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae683d6",
   "metadata": {},
   "source": [
    "## - The derivative for a tensor x must match the shape of the x tensor\n",
    "## - When we take tensor.f(dim=1) we take the f over the rows, otherwise over cols\n",
    "## - Every time you have a sum in the foward pass, you have a replication/broadcasting in the backward pass along the same dimension.\n",
    "## - When we have a replication/broadcasting in the foward pass this implies a variable reuse which is handled in the backward pass via a sum over the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12400dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# We start from dloss/dloss = 1\n",
    "# Given: \n",
    "# loss = -logprobs[range(n), Yb].mean(); \n",
    "# compute:\n",
    "# dloss/dlogprob \n",
    "\n",
    "# idea: l = -(a+b+c)/3\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1./n \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "assert logprobs.shape == dlogprobs.shape\n",
    "\n",
    "# dloss/dlogprob = -1/n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89511650",
   "metadata": {},
   "source": [
    "Summing the gradients due to individual samples you get a much smoother gradient. The larger the batch the smoother the resulting gradient used in updating the weight.\n",
    "\n",
    "Dividing the sum by the batch size and taking the average gradient has the effect of:\n",
    "\n",
    "1) The magnitude of the weight does not grow out of proportion. Adding L2 regularization to the weight update penalizes large weight values. This often leads to improved generalization performance. Taking the average, especially if the gradients happen to point in the same direction, keep the weights from getting too large.\n",
    "\n",
    "2) The magnitude of the gradient is independent of the batch size. This allows comparison of weights from other experiments using different batch sizes.\n",
    "\n",
    "3) Countering the effect of the batch size with the learning rate can be numerically equivalent but you end up with a learning rate that is implementation specific. It makes it difficult to communicate your results and experimental setup if people cannot relate to the scale of parameters you're using and they'll have trouble reproducing your experiment.\n",
    "\n",
    "Averaging enables clearer comparability and keeping gradient magnitudes independent of batch size. Choosing a batch size is sometimes constrained by the computational resources you have and you want to mitigate the effect of this when evaluating your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62962fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# logprobs = probs.log()\n",
    "# compute:\n",
    "# dloss/dprobs = dloss/dlogprob * dlogprob/dprobs\n",
    " \n",
    "# rule: d' log(x) = 1/x\n",
    "dprobs =  dlogprobs * 1.0/probs # element-wise operations, chained grad * local derivative\n",
    "# the idea: if obs[i] is being correctly classified then probs[i]=1 -> 1/1*chained grad\n",
    "# the grad is passed thru. What does it mean for the grad to be passed thru?\n",
    "\n",
    "# On the other hand if obs[i] is being misclassified then probs[i]<1 \n",
    "# which implies that 1/probs[i] is large -> then grad is boosted, s.t. increase the magnitude of the \n",
    "# change that has to be apported to the weights s.t. classify correctly\n",
    "\n",
    "# the application of the log acts as: \n",
    "# \"identity func\" on the grad for all the correct predictions and as a \n",
    "# grad booster for all the incorrect predictions\n",
    "\n",
    "cmp('probs', dprobs, probs)\n",
    "assert probs.shape == dprobs.shape\n",
    "\n",
    "# dprobs =  -1/n * 1/probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96580dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts_sum_inv | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# probs = counts * counts_sum_inv\n",
    "# compute:\n",
    "# dloss/dcounts_sum_inv = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv\n",
    "\n",
    "# pytorch does 2 things here:\n",
    "\n",
    "    # 1) broadcasting to perform multiplication cuz:\n",
    "    # counts.shape, counts_sum_inv.shape\n",
    "    # (torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "    # so counts_sum_inv is replicated multiple time across the cols\n",
    "\n",
    "    # 2) the multiplication itself is performed\n",
    "\n",
    "    \n",
    "# toy example:\n",
    "# c = a * b \n",
    "# with a[3x3], b[3x1]\n",
    "# a11, a12, a13    b1     a11*b1 a12*b1 a13*b1\n",
    "# a21, a22, a23 *  b2  =  a21*b2 a22*b2 a23*b2\n",
    "# a31, a32, a33    b3     a31*b3 a32*b3 a33*b3\n",
    "\n",
    "# where b1=unnormalized prob of the first row (i.e. of the first example) \n",
    "# where b2=unnormalized prob of the second row (i.e. of the second example)\n",
    "# where b3=unnormalized prob of the second row (i.e. of the second example)\n",
    "\n",
    "# as we can see b1 is used 3 times in the first row, b2 3 times in the sec row, etc\n",
    "# thus b_i is used X times and thus its gradient its the sum of its X local derivatives \n",
    "# eg for b1: a11, a12, a13 -> sum the cols\n",
    "\n",
    "dstep1 = dprobs * counts\n",
    "dstep2 = dstep1.sum(1, keepdim=True)\n",
    "dcounts_sum_inv = dstep2\n",
    "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "assert counts_sum_inv.shape == dcounts_sum_inv.shape\n",
    "\n",
    "# dcounts_sum_inv = -1/n * 1/probs * counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aadbf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# probs = counts * counts_sum_inv \n",
    "# compute:\n",
    "# dloss/dcounts = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts\n",
    "\n",
    "print(dprobs.shape, counts_sum_inv.shape) # broadcasting makes shapes ok\n",
    "dcounts = dprobs * counts_sum_inv\n",
    "assert dcounts.shape == counts.shape\n",
    "\n",
    "# we can't check yet cuz dcounts because counts is also used to compute counts_sum, and thus also the grad\n",
    "# from this other branch of the computational graph has to be computed before checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ac957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts_sum     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# compute:\n",
    "# dloss/dcounts_sum = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv * dcounts_sum_inv/dcounts_sum\n",
    "\n",
    "dcounts_sum = -1 * counts_sum**(-2) * dcounts_sum_inv\n",
    "cmp('dcounts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "assert counts_sum.shape == dcounts_sum.shape\n",
    "\n",
    "# dcounts_sum = -1/n * 1/probs * counts * -1/counts_sum**2 = counts/(n*probs*counts_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b26a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcounts         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# compute:\n",
    "# dloss/dcounts = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv * dcounts_sum_inv/dcounts_sum * \n",
    "#     dcounts_sum/dcounts\n",
    "\n",
    "# we already computed part of the counts derivative and it has shape: torch.Size([32, 27]),\n",
    "# given that counts_sum.shape has shape torch.Size([32, 1]) we need to \n",
    "\n",
    "# a11, a12, a13 ---> b1 (= a11 + a12 + a13)\n",
    "# a21, a22, a23 ---> b2 (= a21 + a22 + a23)\n",
    "# a31, a32, a33 ---> b3 (= a31 + a32 + a33)\n",
    "\n",
    "# db1/a11, db1/a12, db1/a13 ---> 1, 1, 1\n",
    "# db2/a21, db2/a22, db2/a23 ---> 1, 1, 1\n",
    "# db3/a31, db3/a32, db3/a33 ---> 1, 1, 1\n",
    "\n",
    "# the sum can be seen as a router for the gradient: the gradient \"coming from above\" is routed \"as-is\" to each\n",
    "# element that is partecipating in the sum.\n",
    "# What happens here thus is the application of dcounts_sum col vector [32, 1] previously computed \n",
    "# replicated over all the cols ||||...|| till it is [32,27]\n",
    "\n",
    "dcounts += torch.ones_like(counts_sum) * dcounts_sum\n",
    "cmp('dcounts', dcounts, counts)\n",
    "assert dcounts.shape == counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bed20705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# counts = norm_logits.exp() \n",
    "# compute:\n",
    "# dloss/dnorm_logits = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv * dcounts_sum_inv/dcounts_sum * \n",
    "#     dcounts_sum/dcounts * dcounts/dnorm_logits\n",
    "\n",
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)\n",
    "assert counts.shape == dnorm_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c48f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "tensor([0.1882, 0.1882, 0.2807, 0.3429]) tensor(1.0000)\n",
      "tensor([0.1882, 0.1882, 0.2807, 0.3429]) tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# norm_logits = logits - logit_maxes \n",
    "# compute:\n",
    "# dloss/dlogits = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv * dcounts_sum_inv/dcounts_sum * \n",
    "#     dcounts_sum/dcounts * dcounts/dnorm_logits * dnorm_logits/dlogits\n",
    "\n",
    "# here we have to be careful with shapes:\n",
    "# (torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "\n",
    "# c11, c12, c13     a11, a12, a13    b1 \n",
    "# c21, c22, c23  =  a21, a22, a23  - b2  \n",
    "# c31, c32, c33     a31, a32, a33    b3 \n",
    "\n",
    "# thus c31 = a31 - b3 ----> +1, -1 \n",
    "\n",
    "dlogits = dnorm_logits.clone() # for saefty\n",
    "# logits are used in the computation of logit_maxes so no check\n",
    "\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True) # for saefty\n",
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "dlogit_maxes.clone().sum() # the grads of logit_maxes actually should be 0, here we are pretty close but not 0\n",
    "# cuz of floating point arithmetic. Why 0? -> cuz we are subtracting logit_maxes to logits just for numerical\n",
    "# stability and we can do this freely cuz with the softmax renormalization we are actually not changing the output \n",
    "# probabilities\n",
    "\n",
    "zi = torch.tensor([.1, .1 , .5, .7])\n",
    "zi_exp = zi.exp()\n",
    "sum_zi_ezp = zi_exp.sum() \n",
    "pdist1 = zi_exp/sum_zi_ezp\n",
    "print(pdist1, pdist1.sum())\n",
    "\n",
    "zi = torch.tensor([.1, .1 , .5, .7])\n",
    "zi -= zi.max()\n",
    "zi_exp = zi.exp()\n",
    "sum_zi_ezp = zi_exp.sum() \n",
    "pdist2 = zi_exp/sum_zi_ezp\n",
    "print(pdist2, pdist2.sum())\n",
    "\n",
    "assert torch.all(pdist1 == pdist2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96753426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# compute:\n",
    "# dloss/dlogits = dloss/dlogprob * dlogprob/dprobs * dprobs/dcounts_sum_inv * dcounts_sum_inv/dcounts_sum * \n",
    "#     dcounts_sum/dcounts * dcounts/dnorm_logits * dnorm_logits/dlogits * dlogits/dlogit_maxes \n",
    "#     * dlogit_maxes/dlogits\n",
    "\n",
    "# care about different shapes:\n",
    "# logits.shape = torch.Size([32, 27]); logit_maxes.shape = torch.Size([32, 1])\n",
    "\n",
    "# logits.max(1, keepdim=True) returns 2 things: 1) the (max) values 2) the indices if these maxes\n",
    "# this is just a selection: local derivative = 1 * the gradient flowing from above\n",
    "\n",
    "dlogits += F.one_hot(logits.max(dim=1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92a3a978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  2, 19, 15, 15, 25, 16,  3, 19,  8, 15,  3, 22,  5,  7,  5,  2,  1,\n",
      "        22, 19, 15, 19, 22, 22, 23,  5, 22, 20, 24,  6, 24, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3dd41d0550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(logits.max(dim=1).indices)\n",
    "plt.imshow(F.one_hot(logits.max(dim=1).indices, num_classes=logits.shape[1])) # * dlogit_maxes\n",
    "# which is equal to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46b50c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3dd39935b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = torch.zeros_like(logits)\n",
    "a[range(n), logits.max(1).indices] = 1\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3730e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32, 64]) torch.Size([64, 27]) torch.Size([27])\n",
      "dh              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# logits = h @ W2 + b2 # output layer\n",
    "# compute:\n",
    "# dloss/dh \n",
    "\n",
    "print(dlogits.shape, h.shape, W2.shape, b2.shape)\n",
    "\n",
    "# let's try to find a toy example to generalize (pen and paper)\n",
    "# but you can also follow the following criteria:\n",
    "\n",
    "# h is [32, 64], so dh will be of the same shape\n",
    "# we already know that dh will be a matrix multiplication between dlogits [32, 27] and\n",
    "# W2 [64, 27], thus the only way to multiply a [32, 27] by a [64, 27] is to transpose the [64, 27] ()\n",
    "\n",
    "dh = dlogits @ W2.T\n",
    "cmp('dh', dh, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ec9c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# logits = h @ W2 + b2 # output layer\n",
    "# compute:\n",
    "# dloss/dW2 \n",
    "\n",
    "# again: h.shape, dlogits.shape: (torch.Size([32, 64]), torch.Size([32, 27]))\n",
    "# thus h.T @ dlogits\n",
    "\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('dW2', dW2, W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be6d44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# logits = h @ W2 + b2 # output layer\n",
    "# compute:\n",
    "# dloss/db2\n",
    "\n",
    "# again here we already know that we need to chain the gradient from dlogits torch.Size([32, 27]))\n",
    "# and since b2 torch.Size([27]) then we know we need to eliminate the first dim of dlogits\n",
    "\n",
    "db2 = dlogits.sum(0, keepdim=True)\n",
    "cmp('db2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34308d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhpreact        | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# h = torch.tanh(hpreact)\n",
    "# compute:\n",
    "# dloss/dhpreact\n",
    "\n",
    "# h.shape == hpreact.shape\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('dhpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ab61a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([1, 64]) torch.Size([32, 64]) torch.Size([1, 64])\n",
      "dbngain         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# hpreact = bngain * bnraw + bnbias \n",
    "# compute:\n",
    "# dloss/dbngain\n",
    "\n",
    "# given that bngain is being broadcasted across the rows, we need to sum all its grads (over the rows )\n",
    "\n",
    "print(hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape)\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True) # torch.Size([1, 64]) = torch.Size([32, 64]) * torch.Size([32, 64])\n",
    "cmp('dbngain', dbngain, bngain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a41716be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnraw          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# hpreact = bngain * bnraw + bnbias \n",
    "# compute:\n",
    "# dloss/dbnraw\n",
    "\n",
    "dbnraw = dhpreact * bngain # cuz bngain here is relplicated/broadcasted just as in its forward pass \n",
    "cmp('dbnraw', dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e50fded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64]) torch.Size([32, 64])\n",
      "dbnbias         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# hpreact = bngain * bnraw + bnbias \n",
    "# compute:\n",
    "# dloss/dbnbias\n",
    "\n",
    "print(bnbias.shape, hpreact.shape)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('dbnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "703b1b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64]) torch.Size([1, 64])\n",
      "dbnvar_inv      | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bnraw = bndiff * bnvar_inv \n",
    "# compute:\n",
    "# dloss/dbndiff\n",
    "# dloss/dbnvar_inv\n",
    "\n",
    "print(dbnraw.shape, bndiff.shape, bnvar_inv.shape)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "# cmp('dbndiff', dbndiff, bndiff) Wrong cuz it is going to be reused, there is another branch\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec8e695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbnvar          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# compute:\n",
    "# dloss/dbnvar\n",
    "\n",
    "dbnvar = -.5 * (bnvar + 1e-5) **-1.5 * dbnvar_inv\n",
    "cmp('dbnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a9958a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64]) torch.Size([32, 64])\n",
      "dbndiff2        | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bnvar = 1/(n-1) * (bndiff2).sum(0, keepdim=True)\n",
    "# compute:\n",
    "# dloss/dbndiff2\n",
    "# corrected var, note: Bessel's correction (dividing by n-1, not n)\n",
    "\n",
    "print(bnvar.shape, bndiff2.shape)\n",
    "\n",
    "# toy example:\n",
    "# b1 = 1/(n-1) * (a11 + a12)\n",
    "# b2 = 1/(n-1) * (a21 + a22)\n",
    "\n",
    "dbndiff2 = 1/(n-1) * dbnvar * torch.ones_like(bndiff2)\n",
    "cmp('dbndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f31668e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbndiff         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bndiff2 = bndiff**2 \n",
    "# compute:\n",
    "# dloss/dbndiff\n",
    "\n",
    "dbndiff += 2 * bndiff * dbndiff2\n",
    "cmp('dbndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e538aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64]) torch.Size([1, 64])\n",
      "dbnmeani        | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bndiff = hprebn - bnmeani\n",
    "# compute:\n",
    "# dloss/dhprebn\n",
    "# dloss/dbnmeani\n",
    "\n",
    "print(bndiff.shape, hprebn.shape, bnmeani.shape )# broadcast -> sum over the same dim, which here is 0\n",
    "\n",
    "dhprebn = dbndiff.clone()\n",
    "# cmp('dhprebn', dhprebn, hprebn) does not work bcuz used again\n",
    "dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "cmp('dbnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1e20880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
    "# compute:\n",
    "# dloss/dhprebn\n",
    "\n",
    "bnmeani.shape, hprebn.shape\n",
    "\n",
    "dhprebn += 1/n * dbnmeani *  torch.ones_like(hprebn)\n",
    "cmp('dhprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "204e32b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 30]) torch.Size([30, 64]) torch.Size([64])\n",
      "dembcat         | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "dW1             | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "db1             | exact: False | approximate: True  | maxdiff: 3.958120942115784e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# hprebn = embcat @ W1 + b1\n",
    "# compute:\n",
    "# dloss/dembcat\n",
    "# dloss/dW1\n",
    "# dloss/db1\n",
    "\n",
    "print(hprebn.shape, embcat.shape, W1.shape, b1.shape)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0, keepdim=True)\n",
    "\n",
    "cmp('dembcat', dembcat, embcat)\n",
    "cmp('dW1', dW1, W1)\n",
    "cmp('db1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd71a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30]) torch.Size([32, 3, 10])\n",
      "demb            | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# embcat = emb.view(emb.shape[0], -1)\n",
    "# compute:\n",
    "# dloss/demb\n",
    "\n",
    "print(dembcat.shape, emb.shape)\n",
    "demb = dembcat.view(emb.shape) # view is just a superficial reshape\n",
    "cmp('demb', demb, emb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "041676bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([32, 3, 10])\n",
      "dC              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Given: \n",
    "# emb = C[Xb]\n",
    "# compute:\n",
    "# dloss/dC\n",
    "\n",
    "# each row-idx of C represents a char and the whole row contains the prob of the next char\n",
    "# for each occurrence of a char in Xb we need an addition\n",
    "print(demb.shape, C[Xb].shape)      \n",
    "# Xb contain indxs to be used to grab the correct entry in C\n",
    "\n",
    "dC = torch.zeros_like(C) # derivative of same shape of the containing dstruct\n",
    "for k in range(Xb.shape[0]): # for each obs in batch\n",
    "    for j in range(Xb.shape[1]): # for each char used in obs\n",
    "        ix = Xb[k,j] # get coords        \n",
    "        dC[ix]+= demb[k,j] # given that emb is just C[Xb] with embeddings replacing chars we can index to pass grad\n",
    "cmp('dC', dC, C) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5943a9",
   "metadata": {},
   "source": [
    "# Exercise 2: manual backprop without splitting softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60bf52f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3410890102386475 diff:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Backprop thru cross_entropy_loss but all in one go\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff: ', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2a34c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 4.889443516731262e-09\n"
     ]
    }
   ],
   "source": [
    "# forward pass cross entropy loss:\n",
    "# we get logits, we apply softmax, we take idx of label and we take prob_i at idx of label,\n",
    "# we apply -log(prob_i) -> average these for the whole batch = cross entropy loss\n",
    "\n",
    "# backward pass cross entropy loss:\n",
    "# dloss/dlogit_i = sum_for_all_i_in_batch/bs [-log(prob_i)] = \n",
    "#                = sum_for_all_i_in_batch/bs -log(e**logit_i/sum_for_all_js e**logit_j) = \n",
    "# where i is the indx of the correct label\n",
    "# step1  set aside the 1/n and extract e**logit_i from the sum and drop log (logx = 1/x)\n",
    "# step2 2 cases: 1 if i == j --> dloss/dlogit_i = 1 - prob_i\n",
    "#                2 if i != j --> dloss/dlogit_i = prob_i\n",
    "# so from our [bs x outclasses] we need to: do nothing if not at correct index, do -1 if at correct index \n",
    "# where prob_i is the prob vector obtained by applying the softmax function to the logits \n",
    "# recalling that the derivative of the sum is the sum of the derivatives we can easly backprop thru the mean\n",
    "# and scale by 1/n\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1 \n",
    "dlogits /= n\n",
    "cmp('dlogits', dlogits, logits) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe9364c",
   "metadata": {},
   "source": [
    "# Intuition behind dlogits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2bc6980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0764, 0.0847, 0.0189, 0.0490, 0.0183, 0.0876, 0.0257, 0.0346, 0.0169,\n",
       "        0.0309, 0.0375, 0.0388, 0.0391, 0.0272, 0.0340, 0.0134, 0.0089, 0.0191,\n",
       "        0.0145, 0.0565, 0.0497, 0.0193, 0.0271, 0.0657, 0.0576, 0.0255, 0.0229],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0] # foward pass results for the first sample in batch\n",
    "# the net is not yet trained so we don't have any real pattern here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfc50fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0764,  0.0847,  0.0189,  0.0490,  0.0183,  0.0876,  0.0257,  0.0346,\n",
       "        -0.9831,  0.0309,  0.0375,  0.0388,  0.0391,  0.0272,  0.0340,  0.0134,\n",
       "         0.0089,  0.0191,  0.0145,  0.0565,  0.0497,  0.0193,  0.0271,  0.0657,\n",
       "         0.0576,  0.0255,  0.0229], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n # backward pass results for the first sample in batch\n",
    "# we can see that the correct probability has a large negative gradient (due to the -1) \n",
    "# while all the other values remained untouched from the forward pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0e9d5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9849e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum() # sums to 0! Idea: for each row we are going to pull down the probabilities at wrong idxs, and \n",
    "# we are going to pull up the probability at the correct index. The ammount of push and pull is equal cuz the \n",
    "# sum of gradients is 0! The \"how much we are pulling\" is given by the magnitudes of out probabilities.  \n",
    "# if we had perfect result then dlogits = torch.zeros\n",
    "# the ammount of how much you prediction is incorrect defines how much push/pull it is going to be done in that \n",
    "# dimension.\n",
    "\n",
    "\n",
    "# Observations:\n",
    "# 1) if the nn is undecided between two classes, i.e. we have a negative gradient due to the -1, but we also have \n",
    "# a very wrong prediction for another class, then what happens is that the grad to diminish the wrongfully labeled\n",
    "# class is equal to the gradient for the correct class\n",
    "\n",
    "# 2) all of this is based on SGD on NegativeLogLikelihood (NLL): recalling that we want \n",
    "# max val in LogLikelihood (LL) -> min on NLL -> step in the direction of a negative grad = decrease loss\n",
    "\n",
    "# 3) Goal: increase Ws that improve loss, decrease Ws that decrease loss\n",
    "# update rule: p.data += - lr * p.grad\n",
    "# if grad < 0 then update to p.data is positive, p increases\n",
    "# if grad > 0 then update to p.data is negative, p decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a80b4472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3dd3035060>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAKTCAYAAADlpSlWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxWElEQVR4nO3dfYyddZk//uvM05kpnRks0E5n+0ABAXl0g1IalUXpUmpCRGqCD8mCIRjdQhYaV9ONirgm3cVE/e4G8Z9dWBOrLhvBaCJGq5SYLbjUEBbFSkuxIG3Rajud6Tyf8/ujP2Yd6QDTucoZPn29kpO0M6fvuc597s993r1n5j6Ver1eDwCAQjQ1egAAgEzKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAorQ0eoA/V6vV4vnnn4/Ozs6oVCqNHgcAmAXq9XocPHgwent7o6np5c/NzLpy8/zzz8fixYsbPQYAMAs9++yzsWjRope9z6wrN52dnRER8fjjj0/8eSYyz/4cPHgwLSsioq2tLS1rZGQkLaurqystKyJ3u71SW5+Oc845Jy3rF7/4RVpWRO5+O1tlXxw9c5uNjY2lZWU+zsz9PyJ3to6OjrSszLmGh4fTsiJyn4P29va0rFqtlpaVvc2y9Pf3xyWXXPKqusGsKzcvHqA6OztTXmRn84vE8VJuMmUeWDL3jYwi/qdm836bRbmZPuVm+jKPsxHHR7nJ3mbZXs1a9wPFAEBRlBsAoCjKDQBQlGNWbu6888449dRTo729PZYvXx4/+9nPjtWXAgCYcEzKzbe+9a1Yt25d3HbbbfHzn/88Lrzwwli1alW88MILx+LLAQBMOCbl5otf/GLceOON8eEPfzjOOeec+OpXvxpz5syJf//3fz8WXw4AYEJ6uRkZGYmtW7fGypUr/++LNDXFypUrY8uWLS+5//DwcPT19U26AQAcrfRy8/vf/z7Gx8djwYIFkz6+YMGC2LNnz0vuv2HDhuju7p64uToxADATDf9tqfXr18eBAwcmbs8++2yjRwIAXsfSr1B88sknR3Nzc+zdu3fSx/fu3Rs9PT0vuX+1Wo1qtZo9BgBwnEo/c9PW1hYXXXRRbNq0aeJjtVotNm3aFCtWrMj+cgAAkxyT95Zat25dXHfddfGWt7wlLr744vjyl78cAwMD8eEPf/hYfDkAgAnHpNxce+218bvf/S4+85nPxJ49e+LNb35zPPDAAy/5IWMAgGzH7F3Bb7rpprjpppuOVTwAwBE1/LelAAAyKTcAQFGO2belZmp8fDzGxsZmnFOv1xOmOay7uzstK+Lw1ZmzNDXl9dT+/v60rIjc5yDzce7cuTMtK/MxRkS0tMzOpVmpVNKyRkdH07IiIs4444y0rO3bt6dlZe4b4+PjaVkRuc9n5mzZ+0amzMdZq9XSskZGRtKyMo+zEXlrYDr7qzM3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCgtjR5gKkNDQ9Ha2jrjnHq9njDNYYODg2lZEbmzNTXl9dRqtZqWFREpz+OLKpVKWlZzc3Na1sjISFpWRMTo6GhaVua+kZmVuV9ERPz6179Oyzr11FPTsrZv356W1dKSe8iu1WppWV1dXWlZQ0NDszIrIncNZK7zzGPj+Ph4WlZE7jZ71V/zNf+KAADHkHIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAitLS6AGm0tTUFE1NM+9etVotYZrDWltb07IiIuXxvahSqaRljYyMpGVF5G630dHRtKzm5ua0rMz9LGJ2z5Yle6729va0rN27d6dlDQ4OpmVlb7PMvIGBgbSsoaGhtKxsp512WlrWU089lZaV+XrS1taWlhWR9/o0ndcSZ24AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUVoaPcBUzjnnnKhUKjPOefrppxOmOWxsbCwtK1utVkvLqlaraVkRudstM6u1tTUtq7m5OS0rW+a+0dSU9/+hzLkiIsbHx9OyFi5cmJb1m9/8Ji0re21mPgctLXkvJ5nrKfu4vX379rSszO2fuc1GR0fTsiLyjrX1ev1V39eZGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJVf/vKX0dnZ2egxJmlpyd1cTU2zs1sODw+n5lUqlbSs9vb2tKyRkZG0rPHx8bSsiIi2trbUvCz1ej0tK3s9Zebt3r07LStzm2WvzVqtlpa1dOnStKydO3emZTU3N6dlZedlHoNGR0fTsrq6utKyIvL22+m8lszOV1cAgKOk3AAARVFuAICiKDcAQFGUGwCgKOnl5rOf/WxUKpVJt7PPPjv7ywAAHNEx+VXwc889N370ox/93xdJ/pVPAICpHJPW0dLSEj09PcciGgDgZR2Tn7l56qmnore3N0477bT40Ic+FLt27ZryvsPDw9HX1zfpBgBwtNLLzfLly+Oee+6JBx54IO66667YuXNnvOMd74iDBw8e8f4bNmyI7u7uidvixYuzRwIAjiOVeua1wY9g//79sXTp0vjiF78YN9xww0s+Pzw8POnSzH19fbF48WJvv9BAs/ntFzKfg8zLlc/mt1/IvMR75qXnsy+L39rampY1NjaWlpW5njLXUkTu2y+ceeaZaVmZb7+Q/RI3W99+IXPfmK1vv3Dw4ME488wz48CBA6844zH/Sd8TTzwxzjzzzNi+ffsRP1+tVqNarR7rMQCA48QxP3XQ398fO3bsiIULFx7rLwUAkF9uPv7xj8fmzZvjmWeeif/+7/+O9773vdHc3Bwf+MAHsr8UAMBLpH9b6rnnnosPfOADsW/fvjjllFPi7W9/ezz88MNxyimnZH8pAICXSC833/zmN7MjAQBetdn56zoAAEdJuQEAijJr3/Qp61fE+/v7E6Y5LPM6GhERhw4dSsvKvPZC9nUh2tvb07Iyr8uRec2cM844Iy0rImLbtm1pWZmPM3PfyLzOUHbeCSeckJaVeamLoaGhtKyI3GvwzNZr08zm9zbMvDZN5uvTVBfdPVpZ13SbzvWnnLkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICitDR6gKmMjo7G6OjojHNaWvIe4vDwcFpWRMSCBQvSsn73u9+lZVWr1bSsiIihoaG0rDlz5qRlDQ4OpmU9+eSTaVkREU1Nef/vGBsbS8uqVCppWR0dHWlZERE9PT1pWU8//XRaVr1eT8vK3P7ZeV1dXWlZfX19aVmZ2z8idz01NzenZWXO1d7enpYVETEyMpKa92o4cwMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCK0tLoAabS1NQUTU0z717j4+MJ0xxWq9XSsiIi9u3bl5aV+TiXLl2alhUR8cwzz6RlNTc3p2VlPp+Zc0VEVCqVtKyWltm5zIeGhlLzduzYkZaVuf0zs7L3s8zjRubjzNTe3p6al7nfztZ949ChQ2lZEY05BjlzAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIrS0ugBpjI2NhZjY2MzzlmyZEnCNIf95je/ScuKiBgfH0/LamnJeyqffvrptKyISHkeX3Tw4MG0rM7OzrSskZGRtKyIiMHBwbSszH0jU/ZclUolNS9Le3t7WlbmWsr2xz/+MS1rzpw5aVn9/f1pWRG5z2fmOm9ubk7Lyl6bWa9108lx5gYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAUpaXRA0xlbGwsxsbGZpyzY8eOhGkOa2rK7YLNzc1pWePj42lZtVotLSsid7bMrIGBgbSs7H0jMy9jHb2oo6MjLWtkZCQtKyJ3PZ1yyilpWX/4wx/SsrL3s7a2trSswcHBtKxFixalZT355JNpWRG5x43MfTZTvV5PzatUKq95jjM3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKMu1y89BDD8VVV10Vvb29UalU4v7775/0+Xq9Hp/5zGdi4cKF0dHREStXroynnnoqa14AgJc17XIzMDAQF154Ydx5551H/Pwdd9wR//Iv/xJf/epX45FHHokTTjghVq1aFUNDQzMeFgDglUz7In6rV6+O1atXH/Fz9Xo9vvzlL8enPvWpeM973hMREV/72tdiwYIFcf/998f73//+l/yb4eHhGB4envh7X1/fdEcCAJiQ+jM3O3fujD179sTKlSsnPtbd3R3Lly+PLVu2HPHfbNiwIbq7uyduixcvzhwJADjOpJabPXv2RETEggULJn18wYIFE5/7c+vXr48DBw5M3J599tnMkQCA40zD31uqWq1GtVpt9BgAQCFSz9z09PRERMTevXsnfXzv3r0TnwMAOJZSy82yZcuip6cnNm3aNPGxvr6+eOSRR2LFihWZXwoA4Iim/W2p/v7+2L59+8Tfd+7cGY899ljMmzcvlixZErfcckt8/vOfjze+8Y2xbNmy+PSnPx29vb1x9dVXZ84NAHBE0y43jz76aLzzne+c+Pu6desiIuK6666Le+65Jz7xiU/EwMBAfOQjH4n9+/fH29/+9njggQeivb09b2oAgClMu9xcdtllUa/Xp/x8pVKJz33uc/G5z31uRoMBABwN7y0FABRFuQEAitLw69xMpampKZqaZt69mpubE6Y5bHx8PC0rIiZdyXmmvv/976dlnXDCCWlZEZHyPL5oZGQkLStT9r5Rq9XSsiqVSlrWn75VymyT+f51mRcTzTwGZWZFRAwODqZldXR0pGU988wzaVljY2NpWRG5az3z2Ji9b2TKOm5M57jozA0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoSkujB5hKvV6Per0+45zx8fGEaQ6rVqtpWRERDzzwQFpWU1NeTx0cHEzLiojo6upKy6rVamlZZ555ZlrWjh070rIicvfb5ubmtKzM/SzzMUbkztbW1paWlXncGBkZScvKNjw8nJbV2tqalpXtDW94Q1rWvn370rIy11PmWorIOwZNJ8eZGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJVKpRKVSmXGOc3NzQnTHNbUlNsFMx7fi2q1WlpWd3d3WlZERH9/f1rW+Ph4Wta2bdvSsrJl7rf1ej0tq7W1NS0rc5+NiDjnnHPSsnbs2JGWdejQobSszGNGRER7e3taVuY6z9z/h4eH07IiIv7whz+kZWWup9ks67VzOvuFMzcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKC2NHmAqbW1t0dbWNuOckZGRhGkOGx0dTcuKiGhvb0/LGhwcTMsaGBhIy4qIqFQqaVkdHR1pWbVaLS1rNmtubk7LWrJkSVrWU089lZYVEbFt27a0rOy1nqW1tTU179ChQ2lZmWuzXq+nZVWr1bSsiNm7b2QezzK3f2be+Pj4q76vMzcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJXzzjsvKpXKjHN+85vfJExz2MjISFpWRMTQ0FBaVsa2elFnZ2daVkTEwYMH07Iyt1lTU163b2nJXUqZz2dm1q5du9KyBgYG0rIicp+DWq2WltXc3JyWNTw8nJYVEVGtVtOyMtdm5jbLfC4jco8bmdu/Xq+nZWXvZ1mzTSfHmRsAoCjKDQBQFOUGACiKcgMAFEW5AQCKMu1y89BDD8VVV10Vvb29UalU4v7775/0+euvvz4qlcqk25VXXpk1LwDAy5p2uRkYGIgLL7ww7rzzzinvc+WVV8bu3bsnbt/4xjdmNCQAwKs17QtDrF69OlavXv2y96lWq9HT03PUQwEAHK1j8jM3Dz74YMyfPz/OOuus+NjHPhb79u2b8r7Dw8PR19c36QYAcLTSy82VV14ZX/va12LTpk3xz//8z7F58+ZYvXp1jI+PH/H+GzZsiO7u7onb4sWLs0cCAI4j6W+/8P73v3/iz+eff35ccMEFcfrpp8eDDz4Yl19++Uvuv379+li3bt3E3/v6+hQcAOCoHfNfBT/ttNPi5JNPju3btx/x89VqNbq6uibdAACO1jEvN88991zs27cvFi5ceKy/FADA9L8t1d/fP+kszM6dO+Oxxx6LefPmxbx58+L222+PNWvWRE9PT+zYsSM+8YlPxBlnnBGrVq1KHRwA4EimXW4effTReOc73znx9xd/Xua6666Lu+66Kx5//PH4j//4j9i/f3/09vbGFVdcEf/4j/+Y+tbuAABTmXa5ueyyy6Jer0/5+R/84AczGggAYCa8txQAUBTlBgAoSvp1brI89thj0dnZOeOc4eHhhGkOmzt3blpWRO5sTU15PTVzroiY8gKOR6NSqaRl1Wq1tKyRkZG0rIhI/Rm13t7etKxdu3alZXV0dKRlReSugUwDAwONHmFKmWu9ra0tLWtsbCwtK3OdR+QezzL32cxt1trampYVEdHc3JySMzo6+qrvOzuPBgAAR0m5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCK0tLoAaby5je/OSqVyoxzfvvb3yZMc9jIyEhaVkREU1NetxwdHU3LypbxPL5ozpw5aVmHDh1Ky6rVamlZEREtLXlL8+mnn07LynycQ0NDaVkREa2trWlZ4+PjaVmZmpubU/MyH2fmbJnH2ra2trSsiIixsbG0rMzjduZxNlvWbNPJceYGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFKWl0QNMZevWrdHZ2TnjnL6+voRpDqtWq2lZEREjIyNpWU1NeT21Xq+nZUVEdHV1pWUNDAykZWU+n7VaLS0rIqK/vz8tq6Ulb5ln7mfj4+NpWRG566mtrS0ta86cOWlZmY8xIqJSqaRlDQ0NpWVlbv/s/ezEE09My9q3b19aVubaHBsbS8uKiFiyZElKznRem5y5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAorQ0eoCpNDU1RVPT7OpetVqt0SNMabZtqz81NjaWltXSkrfLjo6OpmUtW7YsLSsiYufOnWlZzc3NxWdFRAwODqZlZe6z4+PjaVnZx6BKpZKW1d3dnZaV+Vxm6+/vT8tqb29Py8rcZ+v1elpWRMTTTz+dknPw4ME499xzX9V9Z+8rIgDAUVBuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICitDR6gKlUq9WoVqszzhkYGEiY5rB6vZ6WFRHR0pK3+TNnq1QqaVkREUNDQ2lZmbNlbv/t27enZUVEtLe3p2Vlbv/m5ua0rOHh4bSsiIi2trZZmdXf35+Wlb02m5ry/n87ODiYlpW5b2Q+xoiIsbGx1LwsmY/z7LPPTsuKiHjqqadScqZz/HHmBgAoinIDABRFuQEAiqLcAABFUW4AgKJMq9xs2LAh3vrWt0ZnZ2fMnz8/rr766ti2bduk+wwNDcXatWvjpJNOirlz58aaNWti7969qUMDAExlWuVm8+bNsXbt2nj44Yfjhz/8YYyOjsYVV1wx6detb7311vjud78b9957b2zevDmef/75uOaaa9IHBwA4kmld6OOBBx6Y9Pd77rkn5s+fH1u3bo1LL700Dhw4EP/2b/8WGzdujHe9610REXH33XfHm970pnj44YfjkksuyZscAOAIZvQzNwcOHIiIiHnz5kVExNatW2N0dDRWrlw5cZ+zzz47lixZElu2bDlixvDwcPT19U26AQAcraMuN7VaLW655ZZ429veFuedd15EROzZsyfa2trixBNPnHTfBQsWxJ49e46Ys2HDhuju7p64LV68+GhHAgA4+nKzdu3aeOKJJ+Kb3/zmjAZYv359HDhwYOL27LPPzigPADi+HdWb69x0003xve99Lx566KFYtGjRxMd7enpiZGQk9u/fP+nszd69e6Onp+eIWVnvIQUAEDHNMzf1ej1uuummuO++++LHP/5xLFu2bNLnL7roomhtbY1NmzZNfGzbtm2xa9euWLFiRc7EAAAvY1pnbtauXRsbN26M73znO9HZ2TnxczTd3d3R0dER3d3dccMNN8S6deti3rx50dXVFTfffHOsWLHCb0oBAK+JaZWbu+66KyIiLrvsskkfv/vuu+P666+PiIgvfelL0dTUFGvWrInh4eFYtWpVfOUrX0kZFgDglUyr3NTr9Ve8T3t7e9x5551x5513HvVQAABHy3tLAQBFUW4AgKIc1a+CvxbOPffcqFQqM87ZtWtXwjSH1Wq1tKzsvJGRkbSsOXPmpGVFHL4K9WyUuc1ezbdsp2NsbCwtK3M/y3wuM9b3sTI6OpqWlfk4m5ub07Iicvez7u7utKyhoaG0rGyZ6yn7+czyq1/9KjUva5tNJ8eZGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJVHH300Ojs7Z5wzf/78hGkO++1vf5uWFRExMjKSltXUlNdTDx06lJYVEdHV1ZWWNTAwkJZVrVbTsmq1WlpWRMTQ0FBaVktL3jLP3M/Gx8fTsiJy11NbW1ta1ty5c9OyMh9jtj/+8Y9pWZlrM3s/mzdvXlrWvn370rIy12ZmVkREvV5/zXOcuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKK0NHqAqVSr1ahWqzPOqVQqCdMcNjY2lpYVEVGv19Oy2tra0rJGR0fTsiJyt1vmNhseHk7LamnJXUrNzc2peVlqtVqjR5hS5hpoapqd/+/LXpuZjzNz3xgZGUnLypa5zTJfn9rb29Oysvez8fHxlJzp7GOzcwUDABwl5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKEpLoweYytjYWIyNjc045/e//33CNIcdPHgwLSsior29PS1rZGQkLWvOnDlpWRERhw4dSss67bTT0rKefvrptKzx8fG0rIiIrq6utKz9+/enZTU3N6dlZazvP1WpVNKyMtfT0NBQWla2zP22pSXv5SRz32hqyv0//O9+97u0rFNPPTUt64UXXkjLqtVqaVkREdVqNSVnOuvSmRsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQlJZGDzCVjo6O6OjomHFOf39/wjSH1ev1tKyIiJGRkbSspqa8ntra2pqWFZE72zPPPJOWVavV0rIqlUpaVkREX19fWla1Wk3Lyn6cmTKfz0zNzc1pWdmP8U1velNa1pNPPpmWlbnNso/bnZ2daVl79+5Ny2ppyXs5z34NGBwcfM1znLkBAIqi3AAARVFuAICiKDcAQFGUGwCgKNMqNxs2bIi3vvWt0dnZGfPnz4+rr746tm3bNuk+l112WVQqlUm3j370o6lDAwBMZVrlZvPmzbF27dp4+OGH44c//GGMjo7GFVdcEQMDA5Pud+ONN8bu3bsnbnfccUfq0AAAU5nWL8Y/8MADk/5+zz33xPz582Pr1q1x6aWXTnx8zpw50dPTkzMhAMA0zOhnbg4cOBAREfPmzZv08a9//etx8sknx3nnnRfr16+PQ4cOTZkxPDwcfX19k24AAEfrqC9pWKvV4pZbbom3ve1tcd555018/IMf/GAsXbo0ent74/HHH49PfvKTsW3btvj2t799xJwNGzbE7bfffrRjAABMctTlZu3atfHEE0/ET3/600kf/8hHPjLx5/PPPz8WLlwYl19+eezYsSNOP/30l+SsX78+1q1bN/H3vr6+WLx48dGOBQAc546q3Nx0003xve99Lx566KFYtGjRy953+fLlERGxffv2I5abarWa+t43AMDxbVrlpl6vx8033xz33XdfPPjgg7Fs2bJX/DePPfZYREQsXLjwqAYEAJiOaZWbtWvXxsaNG+M73/lOdHZ2xp49eyIioru7Ozo6OmLHjh2xcePGePe73x0nnXRSPP7443HrrbfGpZdeGhdccMExeQAAAH9qWuXmrrvuiojDF+r7U3fffXdcf/310dbWFj/60Y/iy1/+cgwMDMTixYtjzZo18alPfSptYACAlzPtb0u9nMWLF8fmzZtnNBAAwEx4bykAoCjKDQBQlKO+zs2xNjIyEiMjIzPOeaVvpU1HpVJJy4o4fCHELK2trWlZL155OktnZ2da1p+/j9lMZD6fb3zjG9OyIiKefPLJtKzm5ua0rJaWvENG5tqMyH0+M7MyL3UxPDyclhUR8etf/zotK3ObZR4bM/f/iIgTTjghLeuFF15IyxobG0vLyl6bjeDMDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFKWl0QNMZWxsLMbGxmacU6lUEqY5rKUld3MtWrQoLWvXrl1pWZnbLCJicHAwLater6dlZT7OnTt3pmVFRAwPD6dljY+Pp2XVarW0rOz9rLm5eVZmZW7/7GNQ5noaHR1NyzrxxBPTsv74xz+mZUVE7N+/Py0rcz1lPpfZ+1lHR0dKznQ6gTM3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCjKDQBQFOUGACiKcgMAFEW5AQCKotwAAEVRbgCAoig3AEBRlBsAoCgtjR5gKu3t7dHe3j7jnOHh4YRpDhsZGUnLiojYuXNnal6Wc889NzVv27ZtaVmVSiUta3R0NC2rVqulZUVEtLa2pmWNj4+nZWU+znq9npaVnZe5zTo6OtKyBgYG0rIiIqrValpW5jY7ePBgWlZzc3NaVkTufnbCCSekZWUeM/bv35+WFZG3b0zn9dyZGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJXBwcFoaZn5eLVaLWGaw5qbm9OysmXO9sQTT6RlRUS0tramZY2Pj6dlzZ07Ny2rt7c3LSsi4umnn07LqlQqszJrNqtWq2lZhw4dSsvK3v6jo6NpWZmzNTXl/b97bGwsLSsi91g7MDCQlpV5nJ0zZ05aVkTecXs6j9GZGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFAU5QYAKIpyAwAURbkBAIqi3AAARVFuAICiKDcAQFGUGwCgKMoNAFCUlkYPMJW//Mu/jEqlMuOcZ555ZubD/P9GR0fTsiIi2tvb07LGxsbSstra2tKyIiKGhobSsur1elpW5lzbt29Py4qIlH3/RePj42lZmTIfY8Tx8Tgz9/9smceNzMeZeWyMyD1udHV1pWVl7mcHDx5My4qIaGrKOY8ynTXuzA0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKJMq9zcddddccEFF0RXV1d0dXXFihUr4vvf//7E54eGhmLt2rVx0kknxdy5c2PNmjWxd+/e9KEBAKYyrXKzaNGi+Kd/+qfYunVrPProo/Gud70r3vOe98QvfvGLiIi49dZb47vf/W7ce++9sXnz5nj++efjmmuuOSaDAwAcSaU+w6slzZs3L77whS/E+973vjjllFNi48aN8b73vS8iIn71q1/Fm970ptiyZUtccsklR/z3w8PDMTw8PPH3vr6+WLx4cbS2trqI3zRkXqgq64JLL8qcbbZexKxWq6XmNTc3p2UdDxe3i8h9nK2trWlZmbL3/8znYLZexO9PX18yZM42d+7ctKzj4SJ+Bw8ejHPPPTcOHDjwihdAPOqvOD4+Ht/85jdjYGAgVqxYEVu3bo3R0dFYuXLlxH3OPvvsWLJkSWzZsmXKnA0bNkR3d/fEbfHixUc7EgDA9MvN//7v/8bcuXOjWq3GRz/60bjvvvvinHPOiT179kRbW1uceOKJk+6/YMGC2LNnz5R569evjwMHDkzcnn322Wk/CACAF037vaXOOuuseOyxx+LAgQPxX//1X3HdddfF5s2bj3qAarUa1Wr1qP89AMCfmna5aWtrizPOOCMiIi666KL4n//5n/h//+//xbXXXhsjIyOxf//+SWdv9u7dGz09PWkDAwC8nBn/lE+tVovh4eG46KKLorW1NTZt2jTxuW3btsWuXbtixYoVM/0yAACvyrTO3Kxfvz5Wr14dS5YsiYMHD8bGjRvjwQcfjB/84AfR3d0dN9xwQ6xbty7mzZsXXV1dcfPNN8eKFSum/E0pAIBs0yo3L7zwQvzN3/xN7N69O7q7u+OCCy6IH/zgB/HXf/3XERHxpS99KZqammLNmjUxPDwcq1atiq985SvHZHAAgCOZ8XVusvX19UV3d7fr3EyT69w0luvcTJ/r3Eyf69xMn+vcTN9xfZ0bAIDZSLkBAIoy7V8Ff6388pe/jM7OzhnnDA0NJUxzWEdHR1pWRMTg4GBa1gknnJCWlbnNImbvt8wyv5WU+S3GiIiRkZG0rMxtlnnqO3s9ZW6zzG89ZG7/7G9LnXrqqWlZ27ZtS8uaM2dOWlb2t2Uzj7X9/f1pWZmyvy2b9SMd0zlmO3MDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABSlpdED/Ll6vR4REQcPHkzJGxoaSsmJiBgbG0vLiogYHBxMy6rVamlZmdssIne7NTXl9fHMbTY6OpqWFRExMjKSllWpVGZlVvZ6ytxmLx6HMmTus5lzZedlHbMjIsbHx9OyBgYG0rIico8bma8BmVpbW1Pzso6P/f39EfHq9ttKPXu1zNBzzz0XixcvbvQYAMAs9Oyzz8aiRYte9j6zrtzUarV4/vnno7Oz82X/l9jX1xeLFy+OZ599Nrq6ul7DCYmw/RvN9m88z0Fj2f6N1YjtX6/X4+DBg9Hb2/uKZ0Rn3belmpqaXrGR/amuri47dgPZ/o1l+zee56CxbP/Geq23f3d396u6nx8oBgCKotwAAEV53ZabarUat912W1Sr1UaPclyy/RvL9m88z0Fj2f6NNdu3/6z7gWIAgJl43Z65AQA4EuUGACiKcgMAFEW5AQCKotwAAEV5XZabO++8M0499dRob2+P5cuXx89+9rNGj3Tc+OxnPxuVSmXS7eyzz270WMV66KGH4qqrrore3t6oVCpx//33T/p8vV6Pz3zmM7Fw4cLo6OiIlStXxlNPPdWYYQv0Stv/+uuvf8l6uPLKKxszbIE2bNgQb33rW6OzszPmz58fV199dWzbtm3SfYaGhmLt2rVx0kknxdy5c2PNmjWxd+/eBk1cllez/S+77LKXrIGPfvSjDZr4/7zuys23vvWtWLduXdx2223x85//PC688MJYtWpVvPDCC40e7bhx7rnnxu7duyduP/3pTxs9UrEGBgbiwgsvjDvvvPOIn7/jjjviX/7lX+KrX/1qPPLII3HCCSfEqlWr0t/Z/Xj1Sts/IuLKK6+ctB6+8Y1vvIYTlm3z5s2xdu3aePjhh+OHP/xhjI6OxhVXXDHpnb5vvfXW+O53vxv33ntvbN68OZ5//vm45pprGjh1OV7N9o+IuPHGGyetgTvuuKNBE/+J+uvMxRdfXF+7du3E38fHx+u9vb31DRs2NHCq48dtt91Wv/DCCxs9xnEpIur33XffxN9rtVq9p6en/oUvfGHiY/v3769Xq9X6N77xjQZMWLY/3/71er1+3XXX1d/znvc0ZJ7j0QsvvFCPiPrmzZvr9frh/b21tbV+7733TtznySefrEdEfcuWLY0as1h/vv3r9Xr9r/7qr+p/93d/17ihpvC6OnMzMjISW7dujZUrV058rKmpKVauXBlbtmxp4GTHl6eeeip6e3vjtNNOiw996EOxa9euRo90XNq5c2fs2bNn0nro7u6O5cuXWw+voQcffDDmz58fZ511VnzsYx+Lffv2NXqkYh04cCAiIubNmxcREVu3bo3R0dFJa+Dss8+OJUuWWAPHwJ9v/xd9/etfj5NPPjnOO++8WL9+fRw6dKgR400y694V/OX8/ve/j/Hx8ViwYMGkjy9YsCB+9atfNWiq48vy5cvjnnvuibPOOit2794dt99+e7zjHe+IJ554Ijo7Oxs93nFlz549ERFHXA8vfo5j68orr4xrrrkmli1bFjt27Ih/+Id/iNWrV8eWLVuiubm50eMVpVarxS233BJve9vb4rzzzouIw2ugra0tTjzxxEn3tQbyHWn7R0R88IMfjKVLl0Zvb288/vjj8clPfjK2bdsW3/72txs47eus3NB4q1evnvjzBRdcEMuXL4+lS5fGf/7nf8YNN9zQwMngtff+979/4s/nn39+XHDBBXH66afHgw8+GJdffnkDJyvP2rVr44knnvAzfg0y1fb/yEc+MvHn888/PxYuXBiXX3557NixI04//fTXeswJr6tvS5188snR3Nz8kp+E37t3b/T09DRoquPbiSeeGGeeeWZs37690aMcd17c562H2eO0006Lk08+2XpIdtNNN8X3vve9+MlPfhKLFi2a+HhPT0+MjIzE/v37J93fGsg11fY/kuXLl0dENHwNvK7KTVtbW1x00UWxadOmiY/VarXYtGlTrFixooGTHb/6+/tjx44dsXDhwkaPctxZtmxZ9PT0TFoPfX198cgjj1gPDfLcc8/Fvn37rIck9Xo9brrpprjvvvvixz/+cSxbtmzS5y+66KJobW2dtAa2bdsWu3btsgYSvNL2P5LHHnssIqLha+B1922pdevWxXXXXRdvectb4uKLL44vf/nLMTAwEB/+8IcbPdpx4eMf/3hcddVVsXTp0nj++efjtttui+bm5vjABz7Q6NGK1N/fP+l/QDt37ozHHnss5s2bF0uWLIlbbrklPv/5z8cb3/jGWLZsWXz605+O3t7euPrqqxs3dEFebvvPmzcvbr/99lizZk309PTEjh074hOf+EScccYZsWrVqgZOXY61a9fGxo0b4zvf+U50dnZO/BxNd3d3dHR0RHd3d9xwww2xbt26mDdvXnR1dcXNN98cK1asiEsuuaTB07/+vdL237FjR2zcuDHe/e53x0knnRSPP/543HrrrXHppZfGBRdc0NjhG/3rWkfjX//1X+tLliypt7W11S+++OL6ww8/3OiRjhvXXnttfeHChfW2trb6X/zFX9Svvfba+vbt2xs9VrF+8pOf1CPiJbfrrruuXq8f/nXwT3/60/UFCxbUq9Vq/fLLL69v27atsUMX5OW2/6FDh+pXXHFF/ZRTTqm3trbWly5dWr/xxhvre/bsafTYxTjSto+I+t133z1xn8HBwfrf/u3f1t/whjfU58yZU3/ve99b3717d+OGLsgrbf9du3bVL7300vq8efPq1Wq1fsYZZ9T//u//vn7gwIHGDl6v1yv1er3+WpYpAIBj6XX1MzcAAK9EuQEAiqLcAABFUW4AgKIoNwBAUZQbAKAoyg0AUBTlBgAoinIDABRFuQEAiqLcAABF+f8AmdReYXnWed4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Below we have a plot of a grid of size [bs x outclasses]. In the forward pass we can think of logits \n",
    "# as the raw unnormalized probabilities given by the nn.\n",
    "# In the img above we have black squares where we removed a 1 cuz it was the logit of the correct answer, \n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.data, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798c280",
   "metadata": {},
   "source": [
    "# Exercise 3: Derivation of batch norm in 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1df49a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff:  tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / \\\n",
    "    torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "    \n",
    "print('max diff: ', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11d21298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "# dloss/dhprebn given dhpreact (i.e. backprop thru BN layer)\n",
    "\n",
    "dhprebn = bngain * bnvar_inv/n * (n*dhpreact -dhpreact.sum(0) - n/(n-1) * bnraw*(dhpreact*bnraw).sum(0))\n",
    "cmp('dhprebn', dhprebn, hprebn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e34f6",
   "metadata": {},
   "source": [
    "# Exercise 4: Train the MLP neural net with your own backward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3938757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shapes(name, d, g): \n",
    "    print(name, d.shape, g.shape)\n",
    "    assert d.shape == g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e56d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7910\n",
      "  10000/ 200000: 2.1903\n",
      "  20000/ 200000: 2.3417\n",
      "  30000/ 200000: 2.4356\n",
      "  40000/ 200000: 2.0346\n",
      "  50000/ 200000: 2.3475\n",
      "  60000/ 200000: 2.4353\n",
      "  70000/ 200000: 1.9937\n",
      "  80000/ 200000: 2.3515\n",
      "  90000/ 200000: 2.1714\n",
      " 100000/ 200000: 1.9179\n",
      " 110000/ 200000: 2.3189\n",
      " 120000/ 200000: 2.0045\n",
      " 130000/ 200000: 2.3963\n",
      " 140000/ 200000: 2.2860\n",
      " 150000/ 200000: 2.2051\n",
      " 160000/ 200000: 1.9602\n",
      " 170000/ 200000: 1.8293\n",
      " 180000/ 200000: 2.0183\n",
      " 190000/ 200000: 1.9335\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[Xb] # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "        # Linear layer\n",
    "        hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        # -------------------------------------------------------------\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # -------------------------------------------------------------\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        logits = h @ W2 + b2 # output layer\n",
    "        loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "\n",
    "#         for t in [logits, h, W2, bnmean, b2 ,bnvar ,bnvar_inv ,bnraw ,hpreact, hprebn, embcat, emb]: \n",
    "#             t.retain_grad()\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "    #     loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "        # manual backprop! \n",
    "        dC, dW1, db1, dW2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n",
    "\n",
    "        # -----------------\n",
    "        # binary cross entropy backprop\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1 \n",
    "        dlogits /= n\n",
    "        # cmp('dlogits', dlogits, logits) \n",
    "\n",
    "        # second layer backprop\n",
    "        dh = dlogits @ W2.T    \n",
    "        # cmp('dh', dh, h) \n",
    "        dW2 = h.T @ dlogits\n",
    "        # cmp('dW2', dW2, W2) \n",
    "        db2 = dlogits.sum(0, keepdim=True)\n",
    "        # cmp('db2', db2, b2) \n",
    "\n",
    "        # tanh backprop\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        # cmp('dhpreact', dhpreact, hpreact) \n",
    "\n",
    "        # batch norm backprop\n",
    "        dhprebn = bngain * bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1) * bnraw*(dhpreact*bnraw).sum(0))\n",
    "        # cmp('dhprebn', dhprebn, hprebn) \n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True) # torch.Size([1, 64]) = torch.Size([32, 64]) * torch.Size([32, 64])\n",
    "        # cmp('dbngain', dbngain, bngain) \n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "        # cmp('dbnbias', dbnbias, bnbias) \n",
    "\n",
    "        # first layer backprop\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        # cmp('dembcat', dembcat, embcat) \n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        # cmp('dW1', dW1, W1) \n",
    "        db1 = dhprebn.sum(0, keepdim=True)\n",
    "        # cmp('db1', db1, b1) \n",
    "        \n",
    "        # embedding backprop\n",
    "        demb = dembcat.view(emb.shape) # view is just a superficial reshape\n",
    "        # cmp('demb', demb, emb) \n",
    "        dC = torch.zeros_like(C) # derivative of same shape of the containing dstruct\n",
    "        for k in range(Xb.shape[0]): # for each obs in batch\n",
    "            for j in range(Xb.shape[1]): # for each char used in obs\n",
    "                ix = Xb[k,j] # get coords        \n",
    "                dC[ix]+= demb[k,j] # given that emb is just C[Xb] with embeddings replacing chars we can index to pass grad\n",
    "        # cmp('dC', dC, C) \n",
    "\n",
    "        # -----------------    \n",
    "        grads = [dC, dW1, db1.squeeze(), dW2, db2.squeeze(), dbngain, dbnbias]\n",
    "        # -----------------\n",
    "        \n",
    "#         for p, grad in zip(parameters, grads):\n",
    "#             check_shapes(str(tuple(p.shape)), p, grad)\n",
    "\n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads):\n",
    "#             p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "            p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "        # track stats\n",
    "        if i % 10000 == 0: # print every once in a while\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "#         if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55b62435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2090851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0720582008361816\n",
      "val 2.1110851764678955\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = C[x] # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80a69772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayah.\n",
      "see.\n",
      "mad.\n",
      "ryla.\n",
      "rethruthadraegan.\n",
      "chedielin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshub.\n",
      "roshiriel.\n",
      "kindreelynn.\n",
      "nophir.\n",
      "ubented.\n",
      "ryyah.\n",
      "fael.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "        # forward pass\n",
    "        emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "        logits = h @ W2 + b2 # (N, vocab_size)\n",
    "        # sample\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49423702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
